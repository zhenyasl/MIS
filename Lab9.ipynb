{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b877b83d-3b67-44a5-a59e-847a3f6d10d7",
   "metadata": {},
   "source": [
    "10. Train a deep MLP on the MNIST dataset (you can load it using\n",
    "keras.datasets.mnist.load_data(). See if you can get over 98%\n",
    "precision. Try searching for the optimal learning rate by using the\n",
    "approach presented in this chapter (i.e., by growing the learning rate\n",
    "exponentially, plotting the error, and finding the point where the error\n",
    "shoots up). Try adding all the bells and whistlesâ€”save checkpoints, use\n",
    "early stopping, and plot learning curves using TensorBoard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4deb8801-cc1e-406d-a2fb-7312f84619bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1338, 6)\n",
      "(1338,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.read_csv(\"insurance.csv\")\n",
    "\n",
    "num_attribs = [\"age\", \"bmi\", \"children\", \"charges\"]\n",
    "cat_attribs = [\"sex\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "insurance = full_pipeline.fit_transform(df)\n",
    "labels = np.array([1 if x == \"yes\" else 0 for x in df[\"smoker\"]])\n",
    "\n",
    "print(insurance.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79328b11-72a9-46ad-b710-dee1b4d6bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(802, 6)\n",
      "(802,)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(insurance, labels, test_size=0.2, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train,y_train,test_size = 0.25)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "61f345da-0051-4eca-98e5-34d675cf9873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.6965 - accuracy: 0.5299 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.0000e-08\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5299 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.1220e-08\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5299 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.2589e-08\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6965 - accuracy: 0.5299 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.4125e-08\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5299 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.5849e-08\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5299 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.7783e-08\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5312 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 1.9953e-08\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5312 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 2.2387e-08\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6965 - accuracy: 0.5312 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 2.5119e-08\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5312 - val_loss: 0.6875 - val_accuracy: 0.5970 - lr: 2.8184e-08\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5312 - val_loss: 0.6874 - val_accuracy: 0.5970 - lr: 3.1623e-08\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5312 - val_loss: 0.6874 - val_accuracy: 0.5970 - lr: 3.5481e-08\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5337 - val_loss: 0.6874 - val_accuracy: 0.5970 - lr: 3.9811e-08\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5349 - val_loss: 0.6874 - val_accuracy: 0.5970 - lr: 4.4668e-08\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5349 - val_loss: 0.6874 - val_accuracy: 0.5970 - lr: 5.0119e-08\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6964 - accuracy: 0.5362 - val_loss: 0.6874 - val_accuracy: 0.5970 - lr: 5.6234e-08\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5362 - val_loss: 0.6873 - val_accuracy: 0.5970 - lr: 6.3096e-08\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5362 - val_loss: 0.6873 - val_accuracy: 0.5970 - lr: 7.0795e-08\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5362 - val_loss: 0.6873 - val_accuracy: 0.5970 - lr: 7.9433e-08\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6963 - accuracy: 0.5374 - val_loss: 0.6872 - val_accuracy: 0.5970 - lr: 8.9125e-08\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5399 - val_loss: 0.6872 - val_accuracy: 0.6007 - lr: 1.0000e-07\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5411 - val_loss: 0.6872 - val_accuracy: 0.6007 - lr: 1.1220e-07\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6962 - accuracy: 0.5424 - val_loss: 0.6871 - val_accuracy: 0.5970 - lr: 1.2589e-07\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5424 - val_loss: 0.6871 - val_accuracy: 0.5970 - lr: 1.4125e-07\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6961 - accuracy: 0.5436 - val_loss: 0.6870 - val_accuracy: 0.5970 - lr: 1.5849e-07\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.5424 - val_loss: 0.6869 - val_accuracy: 0.5970 - lr: 1.7783e-07\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6960 - accuracy: 0.5424 - val_loss: 0.6869 - val_accuracy: 0.5970 - lr: 1.9953e-07\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6959 - accuracy: 0.5436 - val_loss: 0.6868 - val_accuracy: 0.5970 - lr: 2.2387e-07\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6958 - accuracy: 0.5436 - val_loss: 0.6867 - val_accuracy: 0.5970 - lr: 2.5119e-07\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6957 - accuracy: 0.5461 - val_loss: 0.6866 - val_accuracy: 0.6082 - lr: 2.8184e-07\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6956 - accuracy: 0.5474 - val_loss: 0.6864 - val_accuracy: 0.6082 - lr: 3.1623e-07\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6955 - accuracy: 0.5524 - val_loss: 0.6863 - val_accuracy: 0.6119 - lr: 3.5481e-07\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6954 - accuracy: 0.5511 - val_loss: 0.6862 - val_accuracy: 0.6119 - lr: 3.9811e-07\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6952 - accuracy: 0.5524 - val_loss: 0.6860 - val_accuracy: 0.6119 - lr: 4.4668e-07\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5599 - val_loss: 0.6858 - val_accuracy: 0.6119 - lr: 5.0119e-07\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.5648 - val_loss: 0.6856 - val_accuracy: 0.6231 - lr: 5.6234e-07\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6947 - accuracy: 0.5673 - val_loss: 0.6853 - val_accuracy: 0.6194 - lr: 6.3096e-07\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6945 - accuracy: 0.5723 - val_loss: 0.6851 - val_accuracy: 0.6231 - lr: 7.0795e-07\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.5773 - val_loss: 0.6848 - val_accuracy: 0.6306 - lr: 7.9433e-07\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6940 - accuracy: 0.5860 - val_loss: 0.6844 - val_accuracy: 0.6493 - lr: 8.9125e-07\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6936 - accuracy: 0.6047 - val_loss: 0.6840 - val_accuracy: 0.6754 - lr: 1.0000e-06\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.6197 - val_loss: 0.6836 - val_accuracy: 0.7127 - lr: 1.1220e-06\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6929 - accuracy: 0.6322 - val_loss: 0.6831 - val_accuracy: 0.7276 - lr: 1.2589e-06\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.6384 - val_loss: 0.6826 - val_accuracy: 0.7313 - lr: 1.4125e-06\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6920 - accuracy: 0.6509 - val_loss: 0.6820 - val_accuracy: 0.7500 - lr: 1.5849e-06\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6914 - accuracy: 0.6621 - val_loss: 0.6813 - val_accuracy: 0.7612 - lr: 1.7783e-06\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6908 - accuracy: 0.6771 - val_loss: 0.6805 - val_accuracy: 0.7873 - lr: 1.9953e-06\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6900 - accuracy: 0.6883 - val_loss: 0.6796 - val_accuracy: 0.8022 - lr: 2.2387e-06\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6893 - accuracy: 0.6970 - val_loss: 0.6786 - val_accuracy: 0.8097 - lr: 2.5119e-06\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6884 - accuracy: 0.7120 - val_loss: 0.6776 - val_accuracy: 0.8172 - lr: 2.8184e-06\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6874 - accuracy: 0.7219 - val_loss: 0.6764 - val_accuracy: 0.8209 - lr: 3.1623e-06\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6863 - accuracy: 0.7332 - val_loss: 0.6751 - val_accuracy: 0.8246 - lr: 3.5481e-06\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.7344 - val_loss: 0.6736 - val_accuracy: 0.8246 - lr: 3.9811e-06\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6837 - accuracy: 0.7394 - val_loss: 0.6719 - val_accuracy: 0.8246 - lr: 4.4668e-06\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6822 - accuracy: 0.7431 - val_loss: 0.6701 - val_accuracy: 0.8246 - lr: 5.0119e-06\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6805 - accuracy: 0.7506 - val_loss: 0.6680 - val_accuracy: 0.8246 - lr: 5.6234e-06\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6786 - accuracy: 0.7569 - val_loss: 0.6657 - val_accuracy: 0.8358 - lr: 6.3096e-06\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6765 - accuracy: 0.7631 - val_loss: 0.6630 - val_accuracy: 0.8433 - lr: 7.0795e-06\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6741 - accuracy: 0.7656 - val_loss: 0.6601 - val_accuracy: 0.8433 - lr: 7.9433e-06\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6714 - accuracy: 0.7706 - val_loss: 0.6570 - val_accuracy: 0.8470 - lr: 8.9125e-06\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6685 - accuracy: 0.7756 - val_loss: 0.6534 - val_accuracy: 0.8507 - lr: 1.0000e-05\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6652 - accuracy: 0.7756 - val_loss: 0.6495 - val_accuracy: 0.8507 - lr: 1.1220e-05\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.7756 - val_loss: 0.6451 - val_accuracy: 0.8507 - lr: 1.2589e-05\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.7756 - val_loss: 0.6404 - val_accuracy: 0.8507 - lr: 1.4125e-05\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.7756 - val_loss: 0.6355 - val_accuracy: 0.8507 - lr: 1.5849e-05\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6484 - accuracy: 0.7756 - val_loss: 0.6293 - val_accuracy: 0.8507 - lr: 1.7783e-05\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.7756 - val_loss: 0.6227 - val_accuracy: 0.8507 - lr: 1.9953e-05\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.7756 - val_loss: 0.6157 - val_accuracy: 0.8507 - lr: 2.2387e-05\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.7756 - val_loss: 0.6074 - val_accuracy: 0.8507 - lr: 2.5119e-05\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.7756 - val_loss: 0.5979 - val_accuracy: 0.8507 - lr: 2.8184e-05\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.7756 - val_loss: 0.5882 - val_accuracy: 0.8507 - lr: 3.1623e-05\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.7756 - val_loss: 0.5768 - val_accuracy: 0.8507 - lr: 3.5481e-05\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7756 - val_loss: 0.5632 - val_accuracy: 0.8507 - lr: 3.9811e-05\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7756 - val_loss: 0.5487 - val_accuracy: 0.8507 - lr: 4.4668e-05\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7756 - val_loss: 0.5325 - val_accuracy: 0.8507 - lr: 5.0119e-05\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7756 - val_loss: 0.5137 - val_accuracy: 0.8507 - lr: 5.6234e-05\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7756 - val_loss: 0.4923 - val_accuracy: 0.8507 - lr: 6.3096e-05\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.7756 - val_loss: 0.4678 - val_accuracy: 0.8507 - lr: 7.0795e-05\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.7756 - val_loss: 0.4412 - val_accuracy: 0.8507 - lr: 7.9433e-05\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7930 - val_loss: 0.4129 - val_accuracy: 0.8694 - lr: 8.9125e-05\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8554 - val_loss: 0.3825 - val_accuracy: 0.8843 - lr: 1.0000e-04\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3970 - accuracy: 0.8703 - val_loss: 0.3514 - val_accuracy: 0.8881 - lr: 1.1220e-04\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3665 - accuracy: 0.8853 - val_loss: 0.3238 - val_accuracy: 0.8881 - lr: 1.2589e-04\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3353 - accuracy: 0.8878 - val_loss: 0.2977 - val_accuracy: 0.8806 - lr: 1.4125e-04\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8928 - val_loss: 0.2724 - val_accuracy: 0.8843 - lr: 1.5849e-04\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2753 - accuracy: 0.8903 - val_loss: 0.2530 - val_accuracy: 0.8843 - lr: 1.7783e-04\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2533 - accuracy: 0.8915 - val_loss: 0.2364 - val_accuracy: 0.8918 - lr: 1.9953e-04\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2336 - accuracy: 0.8940 - val_loss: 0.2229 - val_accuracy: 0.8918 - lr: 2.2387e-04\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.8940 - val_loss: 0.2080 - val_accuracy: 0.8843 - lr: 2.5119e-04\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1982 - accuracy: 0.9002 - val_loss: 0.1937 - val_accuracy: 0.8843 - lr: 2.8184e-04\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9002 - val_loss: 0.1799 - val_accuracy: 0.9030 - lr: 3.1623e-04\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1670 - accuracy: 0.9102 - val_loss: 0.1690 - val_accuracy: 0.9104 - lr: 3.5481e-04\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1544 - accuracy: 0.9214 - val_loss: 0.1574 - val_accuracy: 0.9142 - lr: 3.9811e-04\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1443 - accuracy: 0.9214 - val_loss: 0.1501 - val_accuracy: 0.9142 - lr: 4.4668e-04\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9352 - val_loss: 0.1440 - val_accuracy: 0.9291 - lr: 5.0119e-04\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1280 - accuracy: 0.9389 - val_loss: 0.1383 - val_accuracy: 0.9291 - lr: 5.6234e-04\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.9401 - val_loss: 0.1347 - val_accuracy: 0.9291 - lr: 6.3096e-04\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9426 - val_loss: 0.1301 - val_accuracy: 0.9328 - lr: 7.0795e-04\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1124 - accuracy: 0.9439 - val_loss: 0.1293 - val_accuracy: 0.9366 - lr: 7.9433e-04\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.9476 - val_loss: 0.1269 - val_accuracy: 0.9366 - lr: 8.9125e-04\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9514 - val_loss: 0.1343 - val_accuracy: 0.9328 - lr: 0.0010\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.1015 - accuracy: 0.9514 - val_loss: 0.1221 - val_accuracy: 0.9366 - lr: 0.0011\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0988 - accuracy: 0.9551 - val_loss: 0.1171 - val_accuracy: 0.9403 - lr: 0.0013\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0949 - accuracy: 0.9601 - val_loss: 0.1139 - val_accuracy: 0.9440 - lr: 0.0014\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9576 - val_loss: 0.1137 - val_accuracy: 0.9366 - lr: 0.0016\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9626 - val_loss: 0.1107 - val_accuracy: 0.9440 - lr: 0.0018\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9564 - val_loss: 0.1041 - val_accuracy: 0.9515 - lr: 0.0020\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0886 - accuracy: 0.9613 - val_loss: 0.1057 - val_accuracy: 0.9515 - lr: 0.0022\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9613 - val_loss: 0.1005 - val_accuracy: 0.9515 - lr: 0.0025\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0832 - accuracy: 0.9613 - val_loss: 0.1027 - val_accuracy: 0.9515 - lr: 0.0028\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9638 - val_loss: 0.1009 - val_accuracy: 0.9515 - lr: 0.0032\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9663 - val_loss: 0.1314 - val_accuracy: 0.9291 - lr: 0.0035\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9651 - val_loss: 0.1009 - val_accuracy: 0.9552 - lr: 0.0040\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0866 - accuracy: 0.9626 - val_loss: 0.1031 - val_accuracy: 0.9590 - lr: 0.0045\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9589 - val_loss: 0.0805 - val_accuracy: 0.9664 - lr: 0.0050\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0954 - accuracy: 0.9638 - val_loss: 0.1123 - val_accuracy: 0.9440 - lr: 0.0056\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9688 - val_loss: 0.1076 - val_accuracy: 0.9590 - lr: 0.0063\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9626 - val_loss: 0.0922 - val_accuracy: 0.9590 - lr: 0.0071\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9663 - val_loss: 0.0980 - val_accuracy: 0.9515 - lr: 0.0079\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0736 - accuracy: 0.9701 - val_loss: 0.0916 - val_accuracy: 0.9627 - lr: 0.0089\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0735 - accuracy: 0.9713 - val_loss: 0.0924 - val_accuracy: 0.9590 - lr: 0.0100\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9688 - val_loss: 0.0849 - val_accuracy: 0.9627 - lr: 0.0112\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0611 - accuracy: 0.9713 - val_loss: 0.1059 - val_accuracy: 0.9515 - lr: 0.0126\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9638 - val_loss: 0.0930 - val_accuracy: 0.9552 - lr: 0.0141\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9589 - val_loss: 0.0824 - val_accuracy: 0.9739 - lr: 0.0158\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1580 - accuracy: 0.9489 - val_loss: 0.1100 - val_accuracy: 0.9627 - lr: 0.0178\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1224 - accuracy: 0.9489 - val_loss: 0.1051 - val_accuracy: 0.9515 - lr: 0.0200\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1120 - accuracy: 0.9564 - val_loss: 0.1058 - val_accuracy: 0.9291 - lr: 0.0224\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.9426 - val_loss: 0.0927 - val_accuracy: 0.9590 - lr: 0.0251\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9601 - val_loss: 0.0860 - val_accuracy: 0.9701 - lr: 0.0282\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9638 - val_loss: 0.0792 - val_accuracy: 0.9701 - lr: 0.0316\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0894 - accuracy: 0.9663 - val_loss: 0.0836 - val_accuracy: 0.9627 - lr: 0.0355\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0983 - accuracy: 0.9589 - val_loss: 0.0835 - val_accuracy: 0.9664 - lr: 0.0398\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.9476 - val_loss: 0.0904 - val_accuracy: 0.9590 - lr: 0.0447\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9613 - val_loss: 0.0938 - val_accuracy: 0.9664 - lr: 0.0501\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0862 - accuracy: 0.9651 - val_loss: 0.0844 - val_accuracy: 0.9664 - lr: 0.0562\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9651 - val_loss: 0.0825 - val_accuracy: 0.9627 - lr: 0.0631\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9576 - val_loss: 0.0957 - val_accuracy: 0.9552 - lr: 0.0708\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0891 - accuracy: 0.9551 - val_loss: 0.0815 - val_accuracy: 0.9664 - lr: 0.0794\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9589 - val_loss: 0.0748 - val_accuracy: 0.9664 - lr: 0.0891\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1166 - accuracy: 0.9526 - val_loss: 0.1016 - val_accuracy: 0.9515 - lr: 0.1000\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1468 - accuracy: 0.9377 - val_loss: 0.1021 - val_accuracy: 0.9552 - lr: 0.1122\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.9464 - val_loss: 0.0882 - val_accuracy: 0.9552 - lr: 0.1259\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9451 - val_loss: 0.0929 - val_accuracy: 0.9515 - lr: 0.1413\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1400 - accuracy: 0.9426 - val_loss: 0.1236 - val_accuracy: 0.9403 - lr: 0.1585\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.7843 - val_loss: 0.3798 - val_accuracy: 0.8955 - lr: 0.1778\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.9631 - accuracy: 0.8728 - val_loss: 0.3826 - val_accuracy: 0.8507 - lr: 0.1995\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.7756 - val_loss: 0.3795 - val_accuracy: 0.8507 - lr: 0.2239\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0475 - accuracy: 0.7756 - val_loss: 0.4228 - val_accuracy: 0.8507 - lr: 0.2512\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7756 - val_loss: 0.4604 - val_accuracy: 0.8507 - lr: 0.2818\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7756 - val_loss: 0.4671 - val_accuracy: 0.8507 - lr: 0.3162\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7756 - val_loss: 0.4622 - val_accuracy: 0.8507 - lr: 0.3548\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7756 - val_loss: 0.5141 - val_accuracy: 0.8507 - lr: 0.3981\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7756 - val_loss: 0.4353 - val_accuracy: 0.8507 - lr: 0.4467\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7756 - val_loss: 0.4327 - val_accuracy: 0.8507 - lr: 0.5012\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7756 - val_loss: 0.4245 - val_accuracy: 0.8507 - lr: 0.5623\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7756 - val_loss: 0.4222 - val_accuracy: 0.8507 - lr: 0.6310\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7756 - val_loss: 0.4246 - val_accuracy: 0.8507 - lr: 0.7079\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7756 - val_loss: 0.4215 - val_accuracy: 0.8507 - lr: 0.7943\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7756 - val_loss: 0.5251 - val_accuracy: 0.8507 - lr: 0.8913\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7756 - val_loss: 0.4217 - val_accuracy: 0.8507 - lr: 1.0000\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5604 - accuracy: 0.7756 - val_loss: 0.4218 - val_accuracy: 0.8507 - lr: 1.1220\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7756 - val_loss: 0.4581 - val_accuracy: 0.8507 - lr: 1.2589\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7756 - val_loss: 0.5473 - val_accuracy: 0.8507 - lr: 1.4125\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.7282 - val_loss: 0.4284 - val_accuracy: 0.8507 - lr: 1.5849\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7756 - val_loss: 0.4223 - val_accuracy: 0.8507 - lr: 1.7783\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5937 - accuracy: 0.7756 - val_loss: 0.4249 - val_accuracy: 0.8507 - lr: 1.9953\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.7756 - val_loss: 0.8027 - val_accuracy: 0.1493 - lr: 2.2387\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5788 - accuracy: 0.7357 - val_loss: 0.4232 - val_accuracy: 0.8507 - lr: 2.5119\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7456 - val_loss: 0.5287 - val_accuracy: 0.8507 - lr: 2.8184\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7756 - val_loss: 0.4491 - val_accuracy: 0.8507 - lr: 3.1623\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6099 - accuracy: 0.7032 - val_loss: 0.4238 - val_accuracy: 0.8507 - lr: 3.5481\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6331 - accuracy: 0.7182 - val_loss: 0.5068 - val_accuracy: 0.8507 - lr: 3.9811\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6858 - val_loss: 0.4272 - val_accuracy: 0.8507 - lr: 4.4668\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7756 - val_loss: 0.4617 - val_accuracy: 0.8507 - lr: 5.0119\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.7057 - val_loss: 0.6338 - val_accuracy: 0.8507 - lr: 5.6234\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6227 - accuracy: 0.7606 - val_loss: 0.4216 - val_accuracy: 0.8507 - lr: 6.3096\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.7756 - val_loss: 0.5350 - val_accuracy: 0.8507 - lr: 7.0795\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.8043 - accuracy: 0.6459 - val_loss: 0.4659 - val_accuracy: 0.8507 - lr: 7.9433\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.9424 - accuracy: 0.6833 - val_loss: 1.0833 - val_accuracy: 0.1493 - lr: 8.9125\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6998 - accuracy: 0.6783 - val_loss: 0.6105 - val_accuracy: 0.8507 - lr: 10.0000\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0061 - accuracy: 0.6633 - val_loss: 0.6311 - val_accuracy: 0.8507 - lr: 11.2202\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.1365 - accuracy: 0.6309 - val_loss: 0.8371 - val_accuracy: 0.8507 - lr: 12.5893\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.2330 - accuracy: 0.6933 - val_loss: 5.1363 - val_accuracy: 0.1493 - lr: 14.1254\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.9930 - accuracy: 0.6209 - val_loss: 0.4283 - val_accuracy: 0.8507 - lr: 15.8489\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.7182 - val_loss: 0.6946 - val_accuracy: 0.8507 - lr: 17.7828\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.7660 - accuracy: 0.7481 - val_loss: 0.4487 - val_accuracy: 0.8507 - lr: 19.9526\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0505 - accuracy: 0.6484 - val_loss: 2.4803 - val_accuracy: 0.1493 - lr: 22.3872\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.0083 - accuracy: 0.6908 - val_loss: 0.5584 - val_accuracy: 0.8507 - lr: 25.1189\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.8475 - accuracy: 0.6833 - val_loss: 0.9416 - val_accuracy: 0.8507 - lr: 28.1838\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.8300 - accuracy: 0.6559 - val_loss: 2.7236 - val_accuracy: 0.8507 - lr: 31.6228\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2.5865 - accuracy: 0.6334 - val_loss: 1.5015 - val_accuracy: 0.1493 - lr: 35.4813\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1.6163 - accuracy: 0.6409 - val_loss: 1.0742 - val_accuracy: 0.1493 - lr: 39.8107\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.4908 - accuracy: 0.6359 - val_loss: 8.3982 - val_accuracy: 0.1493 - lr: 44.6684\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.5467 - accuracy: 0.6334 - val_loss: 4.3535 - val_accuracy: 0.8507 - lr: 50.1187\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.4753 - accuracy: 0.6858 - val_loss: 2.0061 - val_accuracy: 0.8507 - lr: 56.2341\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 5.6366 - accuracy: 0.6758 - val_loss: 3.4951 - val_accuracy: 0.8507 - lr: 63.0957\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.2251 - accuracy: 0.6833 - val_loss: 0.7075 - val_accuracy: 0.8507 - lr: 70.7946\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 5.0389 - accuracy: 0.6384 - val_loss: 2.7460 - val_accuracy: 0.1493 - lr: 79.4328\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.7075 - accuracy: 0.6060 - val_loss: 2.8721 - val_accuracy: 0.8507 - lr: 89.1251\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.6288 - accuracy: 0.6758 - val_loss: 1.3327 - val_accuracy: 0.8507 - lr: 100.0000\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.7918 - accuracy: 0.6633 - val_loss: 0.5085 - val_accuracy: 0.8507 - lr: 112.2018\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3.6972 - accuracy: 0.6633 - val_loss: 5.7965 - val_accuracy: 0.1493 - lr: 125.8925\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 22.6795 - accuracy: 0.6708 - val_loss: 8.7219 - val_accuracy: 0.1493 - lr: 141.2538\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 28.7041 - accuracy: 0.6908 - val_loss: 19.7135 - val_accuracy: 0.1493 - lr: 158.4893\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.6600 - accuracy: 0.6783 - val_loss: 4.4466 - val_accuracy: 0.8507 - lr: 177.8279\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 16.2860 - accuracy: 0.6559 - val_loss: 2.1858 - val_accuracy: 0.8507 - lr: 199.5262\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8.1820 - accuracy: 0.6534 - val_loss: 1.2256 - val_accuracy: 0.8507 - lr: 223.8721\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 6.0207 - accuracy: 0.6783 - val_loss: 4.6814 - val_accuracy: 0.8507 - lr: 251.1886\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7.2922 - accuracy: 0.6534 - val_loss: 1.9235 - val_accuracy: 0.8507 - lr: 281.8383\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 28.5004 - accuracy: 0.6309 - val_loss: 9.4082 - val_accuracy: 0.8507 - lr: 316.2278\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 27.0153 - accuracy: 0.6110 - val_loss: 60.5625 - val_accuracy: 0.8507 - lr: 354.8134\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 73.3962 - accuracy: 0.6584 - val_loss: 11.0903 - val_accuracy: 0.8507 - lr: 398.1072\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 29.9287 - accuracy: 0.6584 - val_loss: 28.0922 - val_accuracy: 0.8507 - lr: 446.6836\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 36.2531 - accuracy: 0.6608 - val_loss: 50.3290 - val_accuracy: 0.8507 - lr: 501.1872\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 39.7103 - accuracy: 0.6534 - val_loss: 39.9029 - val_accuracy: 0.8507 - lr: 562.3413\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 64.2191 - accuracy: 0.5960 - val_loss: 64.9806 - val_accuracy: 0.8507 - lr: 630.9573\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 58.2449 - accuracy: 0.6858 - val_loss: 14.7751 - val_accuracy: 0.8507 - lr: 707.9458\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 56.2061 - accuracy: 0.6658 - val_loss: 19.1118 - val_accuracy: 0.8507 - lr: 794.3282\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 74.7454 - accuracy: 0.6658 - val_loss: 125.9932 - val_accuracy: 0.1493 - lr: 891.2509\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 52.0190 - accuracy: 0.6409 - val_loss: 75.3236 - val_accuracy: 0.8507 - lr: 1000.0000\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 75.0296 - accuracy: 0.6284 - val_loss: 41.8452 - val_accuracy: 0.8507 - lr: 1122.0184\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 86.7723 - accuracy: 0.6658 - val_loss: 1.9116 - val_accuracy: 0.1493 - lr: 1258.9254\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 94.4467 - accuracy: 0.6608 - val_loss: 89.1714 - val_accuracy: 0.1493 - lr: 1412.5376\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 207.0415 - accuracy: 0.6409 - val_loss: 9.4784 - val_accuracy: 0.8507 - lr: 1584.8932\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 136.5749 - accuracy: 0.6334 - val_loss: 73.8200 - val_accuracy: 0.8507 - lr: 1778.2794\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 109.1073 - accuracy: 0.6085 - val_loss: 131.8965 - val_accuracy: 0.1493 - lr: 1995.2623\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 54.9473 - accuracy: 0.6484 - val_loss: 15.0006 - val_accuracy: 0.8507 - lr: 2238.7212\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 162.7100 - accuracy: 0.6584 - val_loss: 114.4760 - val_accuracy: 0.1493 - lr: 2511.8865\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 198.9869 - accuracy: 0.6683 - val_loss: 41.1797 - val_accuracy: 0.8507 - lr: 2818.3828\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 576.7676 - accuracy: 0.6284 - val_loss: 396.7914 - val_accuracy: 0.8507 - lr: 3162.2776\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 441.5566 - accuracy: 0.6459 - val_loss: 547.2238 - val_accuracy: 0.8507 - lr: 3548.1338\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 505.2434 - accuracy: 0.6509 - val_loss: 26.0897 - val_accuracy: 0.8507 - lr: 3981.0718\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 408.3895 - accuracy: 0.6608 - val_loss: 17.9429 - val_accuracy: 0.8507 - lr: 4466.8359\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 304.6061 - accuracy: 0.6584 - val_loss: 372.0720 - val_accuracy: 0.1493 - lr: 5011.8726\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 329.7365 - accuracy: 0.6658 - val_loss: 121.9932 - val_accuracy: 0.8507 - lr: 5623.4131\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 518.1601 - accuracy: 0.6160 - val_loss: 692.3153 - val_accuracy: 0.8507 - lr: 6309.5732\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 456.4409 - accuracy: 0.6658 - val_loss: 155.4461 - val_accuracy: 0.8507 - lr: 7079.4580\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 500.5444 - accuracy: 0.6608 - val_loss: 10.9399 - val_accuracy: 0.8507 - lr: 7943.2822\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 424.8368 - accuracy: 0.6608 - val_loss: 415.5428 - val_accuracy: 0.8507 - lr: 8912.5098\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1180.4966 - accuracy: 0.6559 - val_loss: 890.2418 - val_accuracy: 0.8507 - lr: 10000.0000\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1271.1033 - accuracy: 0.6509 - val_loss: 551.3239 - val_accuracy: 0.8507 - lr: 11220.1846\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 744.3703 - accuracy: 0.6608 - val_loss: 412.9816 - val_accuracy: 0.8507 - lr: 12589.2539\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 815.4635 - accuracy: 0.6459 - val_loss: 292.9633 - val_accuracy: 0.8507 - lr: 14125.3750\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 907.2410 - accuracy: 0.6384 - val_loss: 436.3927 - val_accuracy: 0.8507 - lr: 15848.9316\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1154.2806 - accuracy: 0.6359 - val_loss: 1023.4172 - val_accuracy: 0.8507 - lr: 17782.7949\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1025.5358 - accuracy: 0.6683 - val_loss: 750.6943 - val_accuracy: 0.8507 - lr: 19952.6230\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1232.5219 - accuracy: 0.6608 - val_loss: 361.1561 - val_accuracy: 0.8507 - lr: 22387.2109\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1524.8970 - accuracy: 0.6708 - val_loss: 184.6349 - val_accuracy: 0.8507 - lr: 25118.8652\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1564.4337 - accuracy: 0.6933 - val_loss: 3446.0645 - val_accuracy: 0.1493 - lr: 28183.8301\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2035.3892 - accuracy: 0.6359 - val_loss: 677.8271 - val_accuracy: 0.8507 - lr: 31622.7773\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3370.0168 - accuracy: 0.6683 - val_loss: 2122.1741 - val_accuracy: 0.8507 - lr: 35481.3398\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 2380.2227 - accuracy: 0.6509 - val_loss: 904.1542 - val_accuracy: 0.8507 - lr: 39810.7188\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1683.6497 - accuracy: 0.6633 - val_loss: 2711.4348 - val_accuracy: 0.1493 - lr: 44668.3594\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 1841.3547 - accuracy: 0.6060 - val_loss: 2973.8945 - val_accuracy: 0.8507 - lr: 50118.7227\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3921.7222 - accuracy: 0.6284 - val_loss: 3475.1750 - val_accuracy: 0.8507 - lr: 56234.1328\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 3448.0835 - accuracy: 0.6534 - val_loss: 1418.5568 - val_accuracy: 0.8507 - lr: 63095.7344\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7148.4365 - accuracy: 0.6708 - val_loss: 4203.3740 - val_accuracy: 0.8507 - lr: 70794.5781\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 4524.4375 - accuracy: 0.6559 - val_loss: 1353.7961 - val_accuracy: 0.8507 - lr: 79432.8203\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 4112.8638 - accuracy: 0.6309 - val_loss: 275.4619 - val_accuracy: 0.1493 - lr: 89125.0938\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 4599.8896 - accuracy: 0.6434 - val_loss: 2527.2100 - val_accuracy: 0.8507 - lr: 100000.0000\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7417.8896 - accuracy: 0.6559 - val_loss: 2829.7922 - val_accuracy: 0.8507 - lr: 112201.8438\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8445.8613 - accuracy: 0.6883 - val_loss: 32692.2285 - val_accuracy: 0.1493 - lr: 125892.5391\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 8925.5840 - accuracy: 0.6534 - val_loss: 4510.3535 - val_accuracy: 0.8507 - lr: 141253.7500\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 6201.0352 - accuracy: 0.6584 - val_loss: 10524.5674 - val_accuracy: 0.8507 - lr: 158489.3125\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 7520.0835 - accuracy: 0.6434 - val_loss: 4989.1909 - val_accuracy: 0.8507 - lr: 177827.9375\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 11968.1387 - accuracy: 0.6359 - val_loss: 8359.8555 - val_accuracy: 0.8507 - lr: 199526.2344\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 14318.5361 - accuracy: 0.6509 - val_loss: 1124.3254 - val_accuracy: 0.8507 - lr: 223872.1094\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 10767.6855 - accuracy: 0.6359 - val_loss: 12549.3916 - val_accuracy: 0.8507 - lr: 251188.6406\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 18411.1660 - accuracy: 0.6758 - val_loss: 24209.7324 - val_accuracy: 0.1493 - lr: 281838.2812\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 23482.0430 - accuracy: 0.6459 - val_loss: 29232.5625 - val_accuracy: 0.1493 - lr: 316227.7812\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 22676.6914 - accuracy: 0.6434 - val_loss: 2721.6797 - val_accuracy: 0.8507 - lr: 354813.3750\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 15129.4463 - accuracy: 0.6434 - val_loss: 9918.4785 - val_accuracy: 0.1493 - lr: 398107.1562\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 16165.6758 - accuracy: 0.6010 - val_loss: 24496.4922 - val_accuracy: 0.8507 - lr: 446683.5938\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 31444.9824 - accuracy: 0.6384 - val_loss: 39479.7617 - val_accuracy: 0.8507 - lr: 501187.2188\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 37898.4766 - accuracy: 0.6284 - val_loss: 25557.4668 - val_accuracy: 0.8507 - lr: 562341.3125\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 40842.4375 - accuracy: 0.6683 - val_loss: 218.2521 - val_accuracy: 0.8507 - lr: 630957.3750\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 28514.9297 - accuracy: 0.6758 - val_loss: 7426.9263 - val_accuracy: 0.8507 - lr: 707945.8125\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 24697.3594 - accuracy: 0.6534 - val_loss: 18479.0801 - val_accuracy: 0.8507 - lr: 794328.2500\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 35943.6328 - accuracy: 0.6559 - val_loss: 100863.4766 - val_accuracy: 0.1493 - lr: 891250.9375\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 61253.1133 - accuracy: 0.6284 - val_loss: 65976.1406 - val_accuracy: 0.1493 - lr: 1000000.0000\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 99635.0938 - accuracy: 0.6484 - val_loss: 4960.0737 - val_accuracy: 0.8507 - lr: 1122018.5000\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 65563.6797 - accuracy: 0.6559 - val_loss: 8487.2012 - val_accuracy: 0.8507 - lr: 1258925.3750\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 147193.1719 - accuracy: 0.6284 - val_loss: 95852.1250 - val_accuracy: 0.1493 - lr: 1412537.5000\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 31661.6582 - accuracy: 0.6633 - val_loss: 28002.1875 - val_accuracy: 0.8507 - lr: 1584893.2500\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 85022.9609 - accuracy: 0.6633 - val_loss: 46221.5820 - val_accuracy: 0.1493 - lr: 1778279.3750\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 241184.6406 - accuracy: 0.6434 - val_loss: 6362.3594 - val_accuracy: 0.1493 - lr: 1995262.3750\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 325516.0625 - accuracy: 0.6858 - val_loss: 10857.5830 - val_accuracy: 0.8507 - lr: 2238721.2500\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 134958.9531 - accuracy: 0.6683 - val_loss: 267406.8438 - val_accuracy: 0.1493 - lr: 2511886.5000\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 159478.6875 - accuracy: 0.6185 - val_loss: 58556.4492 - val_accuracy: 0.8507 - lr: 2818383.0000\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 148981.7500 - accuracy: 0.6808 - val_loss: 118854.8984 - val_accuracy: 0.1493 - lr: 3162277.7500\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 177791.4844 - accuracy: 0.6309 - val_loss: 149404.4531 - val_accuracy: 0.8507 - lr: 3548134.0000\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 304957.7500 - accuracy: 0.6758 - val_loss: 88006.5859 - val_accuracy: 0.1493 - lr: 3981071.7500\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 196454.6406 - accuracy: 0.6633 - val_loss: 80876.5078 - val_accuracy: 0.8507 - lr: 4466836.0000\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 299029.0000 - accuracy: 0.6284 - val_loss: 128677.7031 - val_accuracy: 0.8507 - lr: 5011872.5000\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 231554.4531 - accuracy: 0.6733 - val_loss: 104057.8281 - val_accuracy: 0.8507 - lr: 5623413.5000\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 172155.3594 - accuracy: 0.6658 - val_loss: 496476.2812 - val_accuracy: 0.1493 - lr: 6309573.5000\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 554915.3125 - accuracy: 0.6509 - val_loss: 604848.0000 - val_accuracy: 0.8507 - lr: 7079458.0000\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 821270.1875 - accuracy: 0.6484 - val_loss: 760946.1875 - val_accuracy: 0.8507 - lr: 7943282.5000\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 547490.8125 - accuracy: 0.6434 - val_loss: 615093.2500 - val_accuracy: 0.8507 - lr: 8912509.0000\n"
     ]
    }
   ],
   "source": [
    "# Discover learning rate\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(6, input_shape=(6,), activation='relu'),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 1e-8 * 10**(epoch / 20))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-8),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300, callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be684344-f27b-409f-a7f3-251727754332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-08, 0.1, 0.0, 0.3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\n",
    "plt.axis([1e-8, 1e-1, 0, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d72501a-defb-43ef-8007-1fa664c2f022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 1s 7ms/step - loss: 0.3554 - accuracy: 0.8429 - val_loss: 0.2196 - val_accuracy: 0.8918\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1452 - accuracy: 0.9352 - val_loss: 0.1094 - val_accuracy: 0.9366\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9501 - val_loss: 0.1233 - val_accuracy: 0.9478\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9526 - val_loss: 0.0976 - val_accuracy: 0.9552\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9601 - val_loss: 0.1078 - val_accuracy: 0.9328\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9589 - val_loss: 0.0893 - val_accuracy: 0.9515\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9626 - val_loss: 0.0903 - val_accuracy: 0.9590\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9651 - val_loss: 0.0909 - val_accuracy: 0.9590\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9626 - val_loss: 0.0872 - val_accuracy: 0.9590\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9651 - val_loss: 0.0951 - val_accuracy: 0.9478\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0638 - accuracy: 0.9713 - val_loss: 0.0832 - val_accuracy: 0.9478\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9688 - val_loss: 0.0920 - val_accuracy: 0.9478\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9701 - val_loss: 0.0793 - val_accuracy: 0.9515\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0757 - accuracy: 0.9564 - val_loss: 0.0880 - val_accuracy: 0.9478\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 0.9663 - val_loss: 0.0745 - val_accuracy: 0.9515\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0556 - accuracy: 0.9788 - val_loss: 0.0731 - val_accuracy: 0.9590\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9788 - val_loss: 0.0852 - val_accuracy: 0.9590\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9800 - val_loss: 0.0708 - val_accuracy: 0.9627\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9776 - val_loss: 0.0704 - val_accuracy: 0.9515\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0454 - accuracy: 0.9776 - val_loss: 0.0800 - val_accuracy: 0.9552\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0348 - accuracy: 0.9875 - val_loss: 0.0824 - val_accuracy: 0.9590\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9850 - val_loss: 0.0742 - val_accuracy: 0.9664\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9863 - val_loss: 0.1121 - val_accuracy: 0.9664\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0563 - accuracy: 0.9800 - val_loss: 0.0834 - val_accuracy: 0.9590\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9838 - val_loss: 0.0830 - val_accuracy: 0.9590\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9825 - val_loss: 0.0866 - val_accuracy: 0.9590\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9738 - val_loss: 0.0804 - val_accuracy: 0.9590\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0491 - accuracy: 0.9825 - val_loss: 0.0668 - val_accuracy: 0.9701\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0341 - accuracy: 0.9850 - val_loss: 0.0653 - val_accuracy: 0.9552\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 0.9863 - val_loss: 0.0800 - val_accuracy: 0.9664\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 0.0796 - val_accuracy: 0.9664\n",
      "Epoch 32/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9788 - val_loss: 0.0845 - val_accuracy: 0.9664\n",
      "Epoch 33/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9788 - val_loss: 0.0797 - val_accuracy: 0.9664\n",
      "Epoch 34/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0395 - accuracy: 0.9813 - val_loss: 0.0686 - val_accuracy: 0.9701\n",
      "Epoch 35/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0344 - accuracy: 0.9913 - val_loss: 0.0680 - val_accuracy: 0.9739\n",
      "Epoch 36/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0303 - accuracy: 0.9875 - val_loss: 0.1009 - val_accuracy: 0.9627\n",
      "Epoch 37/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 0.0879 - val_accuracy: 0.9664\n",
      "Epoch 38/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.0906 - val_accuracy: 0.9664\n",
      "Epoch 39/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0171 - accuracy: 0.9950 - val_loss: 0.0753 - val_accuracy: 0.9701\n",
      "Epoch 40/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9938 - val_loss: 0.1069 - val_accuracy: 0.9664\n",
      "Epoch 41/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0856 - val_accuracy: 0.9701\n",
      "Epoch 42/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9963 - val_loss: 0.0873 - val_accuracy: 0.9739\n",
      "Epoch 43/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9925 - val_loss: 0.0822 - val_accuracy: 0.9739\n",
      "Epoch 44/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9925 - val_loss: 0.0960 - val_accuracy: 0.9701\n",
      "Epoch 45/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0908 - val_accuracy: 0.9627\n",
      "Epoch 46/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 0.9925 - val_loss: 0.0866 - val_accuracy: 0.9739\n",
      "Epoch 47/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9938 - val_loss: 0.0767 - val_accuracy: 0.9776\n",
      "Epoch 48/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0336 - accuracy: 0.9850 - val_loss: 0.1141 - val_accuracy: 0.9515\n",
      "Epoch 49/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0435 - accuracy: 0.9813 - val_loss: 0.0962 - val_accuracy: 0.9590\n",
      "Epoch 50/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9863 - val_loss: 0.0566 - val_accuracy: 0.9776\n",
      "Epoch 51/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy: 0.9938 - val_loss: 0.0754 - val_accuracy: 0.9701\n",
      "Epoch 52/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.0804 - val_accuracy: 0.9701\n",
      "Epoch 53/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9950 - val_loss: 0.0776 - val_accuracy: 0.9664\n",
      "Epoch 54/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9975 - val_loss: 0.0742 - val_accuracy: 0.9701\n",
      "Epoch 55/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9975 - val_loss: 0.0935 - val_accuracy: 0.9739\n",
      "Epoch 56/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9975 - val_loss: 0.0754 - val_accuracy: 0.9701\n",
      "Epoch 57/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9975 - val_loss: 0.0909 - val_accuracy: 0.9664\n",
      "Epoch 58/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.0947 - val_accuracy: 0.9739\n",
      "Epoch 59/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9963 - val_loss: 0.1027 - val_accuracy: 0.9701\n",
      "Epoch 60/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.1014 - val_accuracy: 0.9627\n",
      "Epoch 61/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9900 - val_loss: 0.0811 - val_accuracy: 0.9664\n",
      "Epoch 62/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9963 - val_loss: 0.1040 - val_accuracy: 0.9739\n",
      "Epoch 63/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9963 - val_loss: 0.1179 - val_accuracy: 0.9664\n",
      "Epoch 64/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9950 - val_loss: 0.1286 - val_accuracy: 0.9739\n",
      "Epoch 65/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9938 - val_loss: 0.0852 - val_accuracy: 0.9739\n",
      "Epoch 66/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9938 - val_loss: 0.0945 - val_accuracy: 0.9701\n",
      "Epoch 67/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9950 - val_loss: 0.0816 - val_accuracy: 0.9701\n",
      "Epoch 68/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0100 - accuracy: 0.9975 - val_loss: 0.1083 - val_accuracy: 0.9701\n",
      "Epoch 69/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9963 - val_loss: 0.1114 - val_accuracy: 0.9664\n",
      "Epoch 70/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9850 - val_loss: 0.1905 - val_accuracy: 0.9590\n",
      "Epoch 71/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9776 - val_loss: 0.0695 - val_accuracy: 0.9627\n",
      "Epoch 72/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9838 - val_loss: 0.0792 - val_accuracy: 0.9776\n",
      "Epoch 73/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9900 - val_loss: 0.0760 - val_accuracy: 0.9776\n",
      "Epoch 74/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9950 - val_loss: 0.0826 - val_accuracy: 0.9701\n",
      "Epoch 75/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9875 - val_loss: 0.1106 - val_accuracy: 0.9590\n",
      "Epoch 76/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.0934 - val_accuracy: 0.9739\n",
      "Epoch 77/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9950 - val_loss: 0.0838 - val_accuracy: 0.9776\n",
      "Epoch 78/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.1062 - val_accuracy: 0.9701\n",
      "Epoch 79/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.1082 - val_accuracy: 0.9739\n",
      "Epoch 80/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9975 - val_loss: 0.1083 - val_accuracy: 0.9739\n",
      "Epoch 81/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1251 - val_accuracy: 0.9701\n",
      "Epoch 82/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1217 - val_accuracy: 0.9701\n",
      "Epoch 83/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.1211 - val_accuracy: 0.9701\n",
      "Epoch 84/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1194 - val_accuracy: 0.9739\n",
      "Epoch 85/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.1237 - val_accuracy: 0.9701\n",
      "Epoch 86/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1194 - val_accuracy: 0.9701\n",
      "Epoch 87/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1324 - val_accuracy: 0.9739\n",
      "Epoch 88/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1438 - val_accuracy: 0.9701\n",
      "Epoch 89/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.1200 - val_accuracy: 0.9701\n",
      "Epoch 90/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.1284 - val_accuracy: 0.9701\n",
      "Epoch 91/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1411 - val_accuracy: 0.9739\n",
      "Epoch 92/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1341 - val_accuracy: 0.9739\n",
      "Epoch 93/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.1347 - val_accuracy: 0.9739\n",
      "Epoch 94/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1318 - val_accuracy: 0.9739\n",
      "Epoch 95/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1205 - val_accuracy: 0.9739\n",
      "Epoch 96/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1205 - val_accuracy: 0.9739\n",
      "Epoch 97/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1250 - val_accuracy: 0.9739\n",
      "Epoch 98/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1236 - val_accuracy: 0.9739\n",
      "Epoch 99/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.1268 - val_accuracy: 0.9739\n",
      "Epoch 100/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1362 - val_accuracy: 0.9739\n",
      "Epoch 101/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1379 - val_accuracy: 0.9739\n",
      "Epoch 102/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1353 - val_accuracy: 0.9701\n",
      "Epoch 103/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1126 - val_accuracy: 0.9739\n",
      "Epoch 104/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1243 - val_accuracy: 0.9739\n",
      "Epoch 105/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1308 - val_accuracy: 0.9739\n",
      "Epoch 106/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1322 - val_accuracy: 0.9739\n",
      "Epoch 107/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1284 - val_accuracy: 0.9739\n",
      "Epoch 108/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1334 - val_accuracy: 0.9739\n",
      "Epoch 109/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1379 - val_accuracy: 0.9739\n",
      "Epoch 110/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1331 - val_accuracy: 0.9739\n",
      "Epoch 111/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1402 - val_accuracy: 0.9739\n",
      "Epoch 112/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1445 - val_accuracy: 0.9739\n",
      "Epoch 113/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1209 - val_accuracy: 0.9739\n",
      "Epoch 114/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1187 - val_accuracy: 0.9739\n",
      "Epoch 115/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1199 - val_accuracy: 0.9739\n",
      "Epoch 116/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1269 - val_accuracy: 0.9739\n",
      "Epoch 117/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1232 - val_accuracy: 0.9701\n",
      "Epoch 118/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1298 - val_accuracy: 0.9739\n",
      "Epoch 119/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1396 - val_accuracy: 0.9739\n",
      "Epoch 120/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1425 - val_accuracy: 0.9739\n",
      "Epoch 121/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1434 - val_accuracy: 0.9739\n",
      "Epoch 122/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1463 - val_accuracy: 0.9739\n",
      "Epoch 123/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1403 - val_accuracy: 0.9739\n",
      "Epoch 124/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1250 - val_accuracy: 0.9739\n",
      "Epoch 125/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1326 - val_accuracy: 0.9739\n",
      "Epoch 126/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1327 - val_accuracy: 0.9739\n",
      "Epoch 127/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1351 - val_accuracy: 0.9739\n",
      "Epoch 128/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.1376 - val_accuracy: 0.9739\n",
      "Epoch 129/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1369 - val_accuracy: 0.9739\n",
      "Epoch 130/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1430 - val_accuracy: 0.9739\n",
      "Epoch 131/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.1464 - val_accuracy: 0.9739\n",
      "Epoch 132/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1496 - val_accuracy: 0.9739\n",
      "Epoch 133/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1383 - val_accuracy: 0.9739\n",
      "Epoch 134/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1531 - val_accuracy: 0.9739\n",
      "Epoch 135/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1659 - val_accuracy: 0.9739\n",
      "Epoch 136/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.1676 - val_accuracy: 0.9739\n",
      "Epoch 137/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1400 - val_accuracy: 0.9776\n",
      "Epoch 138/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1368 - val_accuracy: 0.9776\n",
      "Epoch 139/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.1356 - val_accuracy: 0.9739\n",
      "Epoch 140/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.1298 - val_accuracy: 0.9776\n",
      "Epoch 141/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.1486 - val_accuracy: 0.9739\n",
      "Epoch 142/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.1936 - val_accuracy: 0.9701\n",
      "Epoch 143/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1088 - accuracy: 0.9825 - val_loss: 0.2523 - val_accuracy: 0.9739\n",
      "Epoch 144/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9601 - val_loss: 0.0793 - val_accuracy: 0.9552\n",
      "Epoch 145/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9751 - val_loss: 0.0968 - val_accuracy: 0.9664\n",
      "Epoch 146/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0603 - accuracy: 0.9788 - val_loss: 0.0805 - val_accuracy: 0.9739\n",
      "Epoch 147/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9800 - val_loss: 0.0811 - val_accuracy: 0.9590\n",
      "Epoch 148/300\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.0277 - accuracy: 0.9875 - val_loss: 0.0862 - val_accuracy: 0.9776\n",
      "Epoch 149/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9900 - val_loss: 0.0850 - val_accuracy: 0.9739\n",
      "Epoch 150/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9950 - val_loss: 0.0989 - val_accuracy: 0.9776\n",
      "Epoch 151/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 0.9938 - val_loss: 0.0884 - val_accuracy: 0.9739\n",
      "Epoch 152/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9938 - val_loss: 0.1099 - val_accuracy: 0.9739\n",
      "Epoch 153/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9938 - val_loss: 0.1073 - val_accuracy: 0.9739\n",
      "Epoch 154/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0175 - accuracy: 0.9963 - val_loss: 0.1272 - val_accuracy: 0.9701\n",
      "Epoch 155/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.1142 - val_accuracy: 0.9739\n",
      "Epoch 156/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0115 - accuracy: 0.9963 - val_loss: 0.1102 - val_accuracy: 0.9739\n",
      "Epoch 157/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9963 - val_loss: 0.1104 - val_accuracy: 0.9664\n",
      "Epoch 158/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9963 - val_loss: 0.1144 - val_accuracy: 0.9776\n",
      "Epoch 159/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1226 - val_accuracy: 0.9701\n",
      "Epoch 160/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 0.9975 - val_loss: 0.1217 - val_accuracy: 0.9776\n",
      "Epoch 161/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9963 - val_loss: 0.1342 - val_accuracy: 0.9739\n",
      "Epoch 162/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1296 - val_accuracy: 0.9739\n",
      "Epoch 163/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1320 - val_accuracy: 0.9739\n",
      "Epoch 164/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1394 - val_accuracy: 0.9739\n",
      "Epoch 165/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1445 - val_accuracy: 0.9739\n",
      "Epoch 166/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1426 - val_accuracy: 0.9739\n",
      "Epoch 167/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.1386 - val_accuracy: 0.9739\n",
      "Epoch 168/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 0.9988 - val_loss: 0.1226 - val_accuracy: 0.9701\n",
      "Epoch 169/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1816 - val_accuracy: 0.9701\n",
      "Epoch 170/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1522 - val_accuracy: 0.9739\n",
      "Epoch 171/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1454 - val_accuracy: 0.9739\n",
      "Epoch 172/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1678 - val_accuracy: 0.9739\n",
      "Epoch 173/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0408 - accuracy: 0.9875 - val_loss: 0.1005 - val_accuracy: 0.9776\n",
      "Epoch 174/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9788 - val_loss: 0.1386 - val_accuracy: 0.9366\n",
      "Epoch 175/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 0.9663 - val_loss: 0.0879 - val_accuracy: 0.9701\n",
      "Epoch 176/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0315 - accuracy: 0.9838 - val_loss: 0.0893 - val_accuracy: 0.9701\n",
      "Epoch 177/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9900 - val_loss: 0.0837 - val_accuracy: 0.9776\n",
      "Epoch 178/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.0873 - val_accuracy: 0.9701\n",
      "Epoch 179/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9975 - val_loss: 0.0954 - val_accuracy: 0.9739\n",
      "Epoch 180/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1017 - val_accuracy: 0.9701\n",
      "Epoch 181/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.0967 - val_accuracy: 0.9776\n",
      "Epoch 182/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.1261 - val_accuracy: 0.9739\n",
      "Epoch 183/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9913 - val_loss: 0.1001 - val_accuracy: 0.9776\n",
      "Epoch 184/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9900 - val_loss: 0.0990 - val_accuracy: 0.9813\n",
      "Epoch 185/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9875 - val_loss: 0.1113 - val_accuracy: 0.9776\n",
      "Epoch 186/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1078 - accuracy: 0.9788 - val_loss: 0.0814 - val_accuracy: 0.9701\n",
      "Epoch 187/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0511 - accuracy: 0.9776 - val_loss: 0.0687 - val_accuracy: 0.9739\n",
      "Epoch 188/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9913 - val_loss: 0.0721 - val_accuracy: 0.9739\n",
      "Epoch 189/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0192 - accuracy: 0.9938 - val_loss: 0.0790 - val_accuracy: 0.9739\n",
      "Epoch 190/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9913 - val_loss: 0.1047 - val_accuracy: 0.9664\n",
      "Epoch 191/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0151 - accuracy: 0.9950 - val_loss: 0.0943 - val_accuracy: 0.9701\n",
      "Epoch 192/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0137 - accuracy: 0.9950 - val_loss: 0.1063 - val_accuracy: 0.9701\n",
      "Epoch 193/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.0916 - val_accuracy: 0.9776\n",
      "Epoch 194/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9938 - val_loss: 0.1011 - val_accuracy: 0.9701\n",
      "Epoch 195/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9950 - val_loss: 0.0972 - val_accuracy: 0.9776\n",
      "Epoch 196/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9963 - val_loss: 0.1180 - val_accuracy: 0.9739\n",
      "Epoch 197/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9925 - val_loss: 0.0924 - val_accuracy: 0.9739\n",
      "Epoch 198/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.2300 - accuracy: 0.9514 - val_loss: 0.1030 - val_accuracy: 0.9366\n",
      "Epoch 199/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0997 - accuracy: 0.9638 - val_loss: 0.0916 - val_accuracy: 0.9590\n",
      "Epoch 200/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0671 - accuracy: 0.9738 - val_loss: 0.0992 - val_accuracy: 0.9515\n",
      "Epoch 201/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9726 - val_loss: 0.0884 - val_accuracy: 0.9590\n",
      "Epoch 202/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9763 - val_loss: 0.1013 - val_accuracy: 0.9515\n",
      "Epoch 203/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9788 - val_loss: 0.1149 - val_accuracy: 0.9478\n",
      "Epoch 204/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0462 - accuracy: 0.9788 - val_loss: 0.1142 - val_accuracy: 0.9515\n",
      "Epoch 205/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9776 - val_loss: 0.1079 - val_accuracy: 0.9515\n",
      "Epoch 206/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0722 - accuracy: 0.9763 - val_loss: 0.1090 - val_accuracy: 0.9515\n",
      "Epoch 207/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9813 - val_loss: 0.1175 - val_accuracy: 0.9515\n",
      "Epoch 208/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9838 - val_loss: 0.1161 - val_accuracy: 0.9515\n",
      "Epoch 209/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9850 - val_loss: 0.1138 - val_accuracy: 0.9552\n",
      "Epoch 210/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9888 - val_loss: 0.1120 - val_accuracy: 0.9627\n",
      "Epoch 211/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 0.9888 - val_loss: 0.1184 - val_accuracy: 0.9552\n",
      "Epoch 212/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0277 - accuracy: 0.9888 - val_loss: 0.1178 - val_accuracy: 0.9627\n",
      "Epoch 213/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9875 - val_loss: 0.1178 - val_accuracy: 0.9590\n",
      "Epoch 214/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0246 - accuracy: 0.9888 - val_loss: 0.1254 - val_accuracy: 0.9590\n",
      "Epoch 215/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9913 - val_loss: 0.1226 - val_accuracy: 0.9590\n",
      "Epoch 216/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0220 - accuracy: 0.9925 - val_loss: 0.1200 - val_accuracy: 0.9664\n",
      "Epoch 217/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9913 - val_loss: 0.1232 - val_accuracy: 0.9664\n",
      "Epoch 218/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9938 - val_loss: 0.1287 - val_accuracy: 0.9590\n",
      "Epoch 219/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9938 - val_loss: 0.1277 - val_accuracy: 0.9590\n",
      "Epoch 220/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9726 - val_loss: 0.1017 - val_accuracy: 0.9515\n",
      "Epoch 221/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9863 - val_loss: 0.1070 - val_accuracy: 0.9552\n",
      "Epoch 222/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9825 - val_loss: 0.1114 - val_accuracy: 0.9478\n",
      "Epoch 223/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9813 - val_loss: 0.0932 - val_accuracy: 0.9552\n",
      "Epoch 224/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9913 - val_loss: 0.1096 - val_accuracy: 0.9552\n",
      "Epoch 225/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0963 - accuracy: 0.9676 - val_loss: 0.1178 - val_accuracy: 0.9478\n",
      "Epoch 226/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0710 - accuracy: 0.9713 - val_loss: 0.1061 - val_accuracy: 0.9590\n",
      "Epoch 227/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9738 - val_loss: 0.0962 - val_accuracy: 0.9515\n",
      "Epoch 228/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9763 - val_loss: 0.1017 - val_accuracy: 0.9590\n",
      "Epoch 229/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0550 - accuracy: 0.9751 - val_loss: 0.0914 - val_accuracy: 0.9515\n",
      "Epoch 230/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9813 - val_loss: 0.0990 - val_accuracy: 0.9552\n",
      "Epoch 231/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9763 - val_loss: 0.1007 - val_accuracy: 0.9515\n",
      "Epoch 232/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0492 - accuracy: 0.9800 - val_loss: 0.0926 - val_accuracy: 0.9590\n",
      "Epoch 233/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0481 - accuracy: 0.9825 - val_loss: 0.1023 - val_accuracy: 0.9590\n",
      "Epoch 234/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9800 - val_loss: 0.1041 - val_accuracy: 0.9552\n",
      "Epoch 235/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9813 - val_loss: 0.0947 - val_accuracy: 0.9552\n",
      "Epoch 236/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9838 - val_loss: 0.0991 - val_accuracy: 0.9590\n",
      "Epoch 237/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9813 - val_loss: 0.0988 - val_accuracy: 0.9590\n",
      "Epoch 238/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9838 - val_loss: 0.1087 - val_accuracy: 0.9590\n",
      "Epoch 239/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9800 - val_loss: 0.0962 - val_accuracy: 0.9590\n",
      "Epoch 240/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.9800 - val_loss: 0.0981 - val_accuracy: 0.9552\n",
      "Epoch 241/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9863 - val_loss: 0.1191 - val_accuracy: 0.9515\n",
      "Epoch 242/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9825 - val_loss: 0.1028 - val_accuracy: 0.9627\n",
      "Epoch 243/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9813 - val_loss: 0.0983 - val_accuracy: 0.9627\n",
      "Epoch 244/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9800 - val_loss: 0.1011 - val_accuracy: 0.9552\n",
      "Epoch 245/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9825 - val_loss: 0.1021 - val_accuracy: 0.9627\n",
      "Epoch 246/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9813 - val_loss: 0.1065 - val_accuracy: 0.9590\n",
      "Epoch 247/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9863 - val_loss: 0.1141 - val_accuracy: 0.9515\n",
      "Epoch 248/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0250 - accuracy: 0.9938 - val_loss: 0.1170 - val_accuracy: 0.9664\n",
      "Epoch 249/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0223 - accuracy: 0.9913 - val_loss: 0.1267 - val_accuracy: 0.9590\n",
      "Epoch 250/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 0.1189 - val_accuracy: 0.9590\n",
      "Epoch 251/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0186 - accuracy: 0.9925 - val_loss: 0.1284 - val_accuracy: 0.9552\n",
      "Epoch 252/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9938 - val_loss: 0.1320 - val_accuracy: 0.9590\n",
      "Epoch 253/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0165 - accuracy: 0.9950 - val_loss: 0.1224 - val_accuracy: 0.9627\n",
      "Epoch 254/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.1302 - val_accuracy: 0.9701\n",
      "Epoch 255/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9888 - val_loss: 0.1305 - val_accuracy: 0.9627\n",
      "Epoch 256/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0195 - accuracy: 0.9925 - val_loss: 0.1253 - val_accuracy: 0.9701\n",
      "Epoch 257/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 0.9888 - val_loss: 0.1180 - val_accuracy: 0.9627\n",
      "Epoch 258/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0161 - accuracy: 0.9938 - val_loss: 0.1385 - val_accuracy: 0.9701\n",
      "Epoch 259/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0146 - accuracy: 0.9963 - val_loss: 0.1303 - val_accuracy: 0.9627\n",
      "Epoch 260/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9925 - val_loss: 0.1739 - val_accuracy: 0.9515\n",
      "Epoch 261/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0613 - accuracy: 0.9838 - val_loss: 0.1224 - val_accuracy: 0.9627\n",
      "Epoch 262/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0708 - accuracy: 0.9776 - val_loss: 0.1317 - val_accuracy: 0.9701\n",
      "Epoch 263/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.9900 - val_loss: 0.1354 - val_accuracy: 0.9627\n",
      "Epoch 264/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.1306 - accuracy: 0.9776 - val_loss: 0.1431 - val_accuracy: 0.9552\n",
      "Epoch 265/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9838 - val_loss: 0.1953 - val_accuracy: 0.9590\n",
      "Epoch 266/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9813 - val_loss: 0.1422 - val_accuracy: 0.9590\n",
      "Epoch 267/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9825 - val_loss: 0.1249 - val_accuracy: 0.9478\n",
      "Epoch 268/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9863 - val_loss: 0.0966 - val_accuracy: 0.9590\n",
      "Epoch 269/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9900 - val_loss: 0.1112 - val_accuracy: 0.9627\n",
      "Epoch 270/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0168 - accuracy: 0.9950 - val_loss: 0.1189 - val_accuracy: 0.9627\n",
      "Epoch 271/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9975 - val_loss: 0.1219 - val_accuracy: 0.9627\n",
      "Epoch 272/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0158 - accuracy: 0.9975 - val_loss: 0.1260 - val_accuracy: 0.9627\n",
      "Epoch 273/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.1513 - val_accuracy: 0.9552\n",
      "Epoch 274/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 0.1395 - val_accuracy: 0.9627\n",
      "Epoch 275/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 0.9975 - val_loss: 0.1434 - val_accuracy: 0.9590\n",
      "Epoch 276/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9975 - val_loss: 0.1597 - val_accuracy: 0.9590\n",
      "Epoch 277/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9975 - val_loss: 0.1250 - val_accuracy: 0.9590\n",
      "Epoch 278/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9875 - val_loss: 0.1349 - val_accuracy: 0.9739\n",
      "Epoch 279/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.9813 - val_loss: 0.0896 - val_accuracy: 0.9776\n",
      "Epoch 280/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9925 - val_loss: 0.1374 - val_accuracy: 0.9664\n",
      "Epoch 281/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 0.9950 - val_loss: 0.1287 - val_accuracy: 0.9627\n",
      "Epoch 282/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9963 - val_loss: 0.1473 - val_accuracy: 0.9664\n",
      "Epoch 283/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 0.1428 - val_accuracy: 0.9664\n",
      "Epoch 284/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9975 - val_loss: 0.1460 - val_accuracy: 0.9664\n",
      "Epoch 285/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9963 - val_loss: 0.1449 - val_accuracy: 0.9627\n",
      "Epoch 286/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.1470 - val_accuracy: 0.9664\n",
      "Epoch 287/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9988 - val_loss: 0.1446 - val_accuracy: 0.9739\n",
      "Epoch 288/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.1539 - val_accuracy: 0.9701\n",
      "Epoch 289/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 0.9963 - val_loss: 0.1508 - val_accuracy: 0.9701\n",
      "Epoch 290/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1515 - val_accuracy: 0.9739\n",
      "Epoch 291/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.1522 - val_accuracy: 0.9701\n",
      "Epoch 292/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1605 - val_accuracy: 0.9739\n",
      "Epoch 293/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.1589 - val_accuracy: 0.9739\n",
      "Epoch 294/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9975 - val_loss: 0.1605 - val_accuracy: 0.9739\n",
      "Epoch 295/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0071 - accuracy: 0.9975 - val_loss: 0.1589 - val_accuracy: 0.9627\n",
      "Epoch 296/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0144 - accuracy: 0.9925 - val_loss: 0.1614 - val_accuracy: 0.9664\n",
      "Epoch 297/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9963 - val_loss: 0.1557 - val_accuracy: 0.9739\n",
      "Epoch 298/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 0.9975 - val_loss: 0.1643 - val_accuracy: 0.9739\n",
      "Epoch 299/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 0.9988 - val_loss: 0.1514 - val_accuracy: 0.9739\n",
      "Epoch 300/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.1606 - val_accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "# The best lr is approximately between 1e-3 and 1e-2\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(6, input_shape=(6,), activation='relu'),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=keras.optimizers.Adam(learning_rate=1e-2),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "78815cc2-697e-48dc-bb84-78746488f1fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.1499 - val_accuracy: 0.9701\n",
      "Epoch 2/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 0.9975 - val_loss: 0.1656 - val_accuracy: 0.9701\n",
      "Epoch 3/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 0.9988 - val_loss: 0.1547 - val_accuracy: 0.9701\n",
      "Epoch 4/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1671 - val_accuracy: 0.9701\n",
      "Epoch 5/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1634 - val_accuracy: 0.9701\n",
      "Epoch 6/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1620 - val_accuracy: 0.9701\n",
      "Epoch 7/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.1676 - val_accuracy: 0.9701\n",
      "Epoch 8/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 0.9988 - val_loss: 0.1610 - val_accuracy: 0.9701\n",
      "Epoch 9/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.1685 - val_accuracy: 0.9701\n",
      "Epoch 10/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9988 - val_loss: 0.1554 - val_accuracy: 0.9664\n",
      "Epoch 11/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9988 - val_loss: 0.1536 - val_accuracy: 0.9664\n",
      "Epoch 12/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1737 - val_accuracy: 0.9701\n",
      "Epoch 13/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1586 - val_accuracy: 0.9701\n",
      "Epoch 14/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 0.9988 - val_loss: 0.1540 - val_accuracy: 0.9739\n",
      "Epoch 15/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.1572 - val_accuracy: 0.9664\n",
      "Epoch 16/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1624 - val_accuracy: 0.9701\n",
      "Epoch 17/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1671 - val_accuracy: 0.9701\n",
      "Epoch 18/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1685 - val_accuracy: 0.9664\n",
      "Epoch 19/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.1697 - val_accuracy: 0.9701\n",
      "Epoch 20/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1751 - val_accuracy: 0.9701\n",
      "Epoch 21/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1801 - val_accuracy: 0.9701\n",
      "Epoch 22/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.1878 - val_accuracy: 0.9701\n",
      "Epoch 23/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1952 - val_accuracy: 0.9701\n",
      "Epoch 24/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1622 - val_accuracy: 0.9701\n",
      "Epoch 25/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9975 - val_loss: 0.1581 - val_accuracy: 0.9701\n",
      "Epoch 26/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1659 - val_accuracy: 0.9701\n",
      "Epoch 27/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.1676 - val_accuracy: 0.9664\n",
      "Epoch 28/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1694 - val_accuracy: 0.9664\n",
      "Epoch 29/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1700 - val_accuracy: 0.9664\n",
      "Epoch 30/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1738 - val_accuracy: 0.9701\n",
      "Epoch 31/300\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.1755 - val_accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=30)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"lab9_model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=300, callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c4bed1b4-3405-41e4-bc2e-410fa64be1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 0.1244 - accuracy: 0.9776\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12441874295473099, 0.9776119589805603]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"lab9_model.h5\") # rollback to best model\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348887b3-1b76-4d6b-83cc-bc55ae8cea9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
